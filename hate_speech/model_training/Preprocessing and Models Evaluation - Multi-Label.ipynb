{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bb8d63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from ftfy import fix_and_explain, apply_plan, fix_text, fix_encoding_and_explain, fix_encoding\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "from tweets_cleaning import ekphrasis_clean\n",
    "from confusion_matrix_utils import plot_confusion_matrix\n",
    "from math import isnan\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3f815c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = Path('../labels/raw')\n",
    "base_models_path = Path('/media/discoD/World_Bank/Nigeria/hate_speech')\n",
    "multi_label_files = ['haaya_tweets_round_2_labeled.csv', \n",
    "                     'ibrahim_tweets_multi_labeled.csv', \n",
    "                     'manu_tweets_round_2_labelled.csv']\n",
    "fourth_path = base_models_path / 'fourth_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "86379bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multilabel_annotations(source_path: Path, clean: bool, drop_labels: bool = True) -> pd.DataFrame:\n",
    "    \n",
    "    multi_label_columns = ['christian|christians', 'muslim|muslims|islam|islamic', \n",
    "                           'northern|northerner|northerners|arewa|almajiri', 'southern|southerner|southerners', \n",
    "                           'hausa|hausas', 'fulani|fulanis', 'yoruba|yorubas', 'igbo|ibo|ibos|igbos', \n",
    "                           'women|woman|girl|girls|female|females', \n",
    "                           'lgbt|lgbtq|lgbtq+|gay|gays|lesbian|lesbians|transgender|transgenders', \n",
    "                           'herdsmen|herdsman', 'eastern|easterner|easterners|biafra']\n",
    "    use_cols = ['text', 'class', 'index'] + multi_label_columns\n",
    "    \n",
    "    dataframe = pd.read_csv(source_path, lineterminator='\\n', usecols=use_cols)\n",
    "    dataframe = dataframe.fillna(0)\n",
    "    dataframe['original_file'] = source_path\n",
    "    \n",
    "    if clean:\n",
    "        dataframe['raw_text'] = dataframe['text']\n",
    "        dataframe['text'] = np.vectorize(ekphrasis_clean)(dataframe['text'], False)\n",
    "    \n",
    "    raw_len = len(dataframe)\n",
    "    print(f'Loaded {len(dataframe)} from {source_path}')\n",
    "    dropped = len(dataframe[dataframe[\"class\"].isnull()])\n",
    "    unsures = len(dataframe[dataframe[\"class\"] == 3])\n",
    "    dataframe = dataframe[dataframe[\"class\"].isin([0,1,2])]\n",
    "    try:\n",
    "        assert (dropped + unsures + len(dataframe)) == raw_len\n",
    "    except AssertionError as ae:\n",
    "        print(f'Empty: {dropped}, Unsure: {unsures}, Remaining: {len(dataframe)}, Raw: {raw_len}')\n",
    "        raise ae\n",
    "    print(f'Dropping {dropped} empties from {source_path}')\n",
    "    print(f'Dropping {unsures} unsures from {source_path}')\n",
    "\n",
    "    dataframe[\"labels\"] = dataframe.apply(lambda row: ','.join([str(label) for label in row[multi_label_columns].tolist()]), axis=1)\n",
    "    if drop_labels:\n",
    "        for column in multi_label_columns:\n",
    "            del dataframe[column]\n",
    "#     del dataframe['class']\n",
    "    \n",
    "    print(dataframe.columns)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def load_multilabel_annotations_from_folder(files_folder: Path, output_path: Path, version: int, \n",
    "                                            clean: bool, drop_labels: bool = True) -> pd.DataFrame:\n",
    "    dataframes = []\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    for file in multi_label_files:\n",
    "        dataframes.append(load_multilabel_annotations(source_path=files_folder / file, clean=clean, \n",
    "                                                      drop_labels=drop_labels))\n",
    "    full_df = pd.concat(dataframes, ignore_index=True)\n",
    "    cleaned_str = '_cleaned' if clean else ''\n",
    "    output_name = output_path / f'multilabels{cleaned_str}_v{version}.tsv'\n",
    "    full_df.to_csv(output_name, index=None, sep='\\t')\n",
    "    print(f'Kept {len(full_df)} labels for training and testing.')\n",
    "    return full_df\n",
    "\n",
    "def load_annotations(output_path: Path, version: int, clean: bool) -> pd.DataFrame:\n",
    "    dataframes = []\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    total_unsure = 0\n",
    "    total_empty = 0\n",
    "    total_raw = 0\n",
    "    for file in files_path.glob(\"*.csv\"):\n",
    "        file_path = str(file)\n",
    "        print(file_path)\n",
    "        class_column = 'second_class' if 'niyati' in file_path else 'class'\n",
    "        use_cols = ['text', class_column, 'index']\n",
    "        try:\n",
    "            dataframe = pd.read_csv(file_path, usecols=use_cols, header=0, lineterminator='\\n')\n",
    "        except UnicodeDecodeError:\n",
    "            dataframe = pd.read_csv(file_path, usecols=use_cols, header=0, lineterminator='\\n', encoding='iso-8859-1')\n",
    "        dataframe = dataframe.rename({class_column: 'labels'}, axis=1)\n",
    "        dataframe['original_file'] = file_path\n",
    "        if clean:\n",
    "            dataframe['raw_text'] = dataframe['text']\n",
    "            dataframe['text'] = np.vectorize(ekphrasis_clean)(dataframe['text'], False)\n",
    "        raw_len = len(dataframe)\n",
    "        print(f'Loaded {len(dataframe)} from {file_path}')\n",
    "        total_raw += len(dataframe)\n",
    "        dropped = len(dataframe[dataframe[\"labels\"].isnull()])\n",
    "        unsures = len(dataframe[dataframe[\"labels\"] == 3])\n",
    "        total_unsure += unsures\n",
    "        total_empty += dropped\n",
    "        dataframe = dataframe[dataframe[\"labels\"].isin([0,1,2])]\n",
    "        try:\n",
    "            assert (dropped + unsures + len(dataframe)) == raw_len\n",
    "        except AssertionError as ae:\n",
    "            print(f'Empty: {dropped}, Unsure: {unsures}, Remaining: {len(dataframe)}, Raw: {raw_len}')\n",
    "            raise ae\n",
    "        print(f'Dropping {dropped} empties from {file_path}')\n",
    "        print(f'Dropping {unsures} unsures from {file_path}')\n",
    "        dataframes.append(dataframe)\n",
    "    full_df = pd.concat(dataframes, ignore_index=True)\n",
    "    if clean:\n",
    "        output_name = output_path / f'labels_cleaned_v{version}.csv'\n",
    "    else:\n",
    "        output_name = output_path / f'labels_v{version}.csv'\n",
    "    full_df.to_csv(output_name, index=None)\n",
    "    print(f'Dropped a total of {total_unsure} unsures and {total_empty} empty labels, keeping {len(full_df)} out of {total_raw} labels.')\n",
    "    return full_df\n",
    "\n",
    "def plot_scores_confusion_matrix(input_path: str, output_name: str):\n",
    "    eval_scores = pd.read_csv(input_path)\n",
    "    gold = eval_scores['labels']\n",
    "    predicted = []\n",
    "    for idx, row in eval_scores.iterrows():\n",
    "        scores = ast.literal_eval(row['score'])\n",
    "        predicted.append(np.argmax(scores))\n",
    "    plot_confusion_matrix(gold, predicted, output_path=f'{output_name}.pdf', none_class=None, size=16)\n",
    "    \n",
    "def get_predicted_label(row) -> float:\n",
    "    return np.argmax(ast.literal_eval(row['score']))\n",
    "\n",
    "def load_scores(input_path: str) -> pd.DataFrame:\n",
    "    eval_scores = pd.read_csv(input_path)\n",
    "    eval_scores['predicted'] = eval_scores.apply(lambda row: get_predicted_label(row), axis=1)\n",
    "    return eval_scores\n",
    "\n",
    "def display_full(dataframe: pd.DataFrame):\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    display(dataframe)\n",
    "    pd.reset_option(\"display.max_colwidth\")\n",
    "    pd.reset_option(\"display.max_columns\")\n",
    "\n",
    "def display_text(dataframe: pd.DataFrame, index: int):\n",
    "    display_full(dataframe.iloc[index][\"text\"])\n",
    "    \n",
    "def bundle_labels(dataframe: pd.DataFrame, label_list: List, output_path: Path) -> pd.DataFrame:\n",
    "    bundled_df = dataframe.copy()\n",
    "    bundled_df['labels'] = bundled_df.apply(lambda row: 1 if row['labels'] in label_list else 0, axis = 1)\n",
    "    bundled_df.to_csv(output_path, index=None)\n",
    "    return bundled_df\n",
    "\n",
    "def dump_prediction_errors(scores_path: Path, output_path: str):\n",
    "    scores_df = load_scores(scores_path / 'scores.csv')\n",
    "    errors_df = scores_df[scores_df['predicted'] != scores_df['labels']]\n",
    "    output_cols = ['labels', 'raw_text', 'score', 'predicted'] if 'cleaned' in str(scores_path) else ['labels', 'text', 'score', 'predicted']\n",
    "    display_full(errors_df[output_cols])\n",
    "    errors_df.to_csv(output_path, line_terminator='\\n', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "dbb574ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>christian|christians</th>\n",
       "      <th>muslim|muslims|islam|islamic</th>\n",
       "      <th>northern|northerner|northerners|arewa|almajiri</th>\n",
       "      <th>southern|southerner|southerners</th>\n",
       "      <th>hausa|hausas</th>\n",
       "      <th>fulani|fulanis</th>\n",
       "      <th>yoruba|yorubas</th>\n",
       "      <th>igbo|ibo|ibos|igbos</th>\n",
       "      <th>women|woman|girl|girls|female|females</th>\n",
       "      <th>lgbt|lgbtq|lgbtq+|gay|gays|lesbian|lesbians|transgender|transgenders</th>\n",
       "      <th>herdsmen|herdsman</th>\n",
       "      <th>eastern|easterner|easterners|biafra</th>\n",
       "      <th>original_file</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @DrOlufunmilayo: What #EndSARS is NOT:\\nIt ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../labels/raw/haaya_tweets_round_2_labeled.csv</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>@MaziNnamdiKanu Aturu hausa. I thought you sai...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../labels/raw/haaya_tweets_round_2_labeled.csv</td>\n",
       "      <td>1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>2</td>\n",
       "      <td>@channelstv @sunrisedailynow @chamberlainusoh ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../labels/raw/haaya_tweets_round_2_labeled.csv</td>\n",
       "      <td>0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>Your one of the lazy almajiris Buhari talked a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../labels/raw/haaya_tweets_round_2_labeled.csv</td>\n",
       "      <td>0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>@olise_c @USEmbassyAbuja @Mazianozie @NigAirFo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../labels/raw/haaya_tweets_round_2_labeled.csv</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>@adamugarba Some of u the educated northerners...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../labels/raw/manu_tweets_round_2_labelled.csv</td>\n",
       "      <td>0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>540</td>\n",
       "      <td>2</td>\n",
       "      <td>“When it comes to relationships, Yoruba boys a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../labels/raw/manu_tweets_round_2_labelled.csv</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>@gloria_adagbon @MBuhari @OlumideIDOWU Lol... ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../labels/raw/manu_tweets_round_2_labelled.csv</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>@Nazirdanhajiya It happens all the time why do...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../labels/raw/manu_tweets_round_2_labelled.csv</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>195</td>\n",
       "      <td>2</td>\n",
       "      <td>@dat_ibadan_boyy @gimbakakanda Some of you Igb...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../labels/raw/manu_tweets_round_2_labelled.csv</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>709 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  class                                               text  \\\n",
       "0      420      0  RT @DrOlufunmilayo: What #EndSARS is NOT:\\nIt ...   \n",
       "1      104      2  @MaziNnamdiKanu Aturu hausa. I thought you sai...   \n",
       "2      226      2  @channelstv @sunrisedailynow @chamberlainusoh ...   \n",
       "3       66      2  Your one of the lazy almajiris Buhari talked a...   \n",
       "4       54      2  @olise_c @USEmbassyAbuja @Mazianozie @NigAirFo...   \n",
       "..     ...    ...                                                ...   \n",
       "704     78      2  @adamugarba Some of u the educated northerners...   \n",
       "705    540      2  “When it comes to relationships, Yoruba boys a...   \n",
       "706    168      1  @gloria_adagbon @MBuhari @OlumideIDOWU Lol... ...   \n",
       "707     26      0  @Nazirdanhajiya It happens all the time why do...   \n",
       "708    195      2  @dat_ibadan_boyy @gimbakakanda Some of you Igb...   \n",
       "\n",
       "     christian|christians  muslim|muslims|islam|islamic  \\\n",
       "0                     0.0                           0.0   \n",
       "1                     1.0                           0.0   \n",
       "2                     0.0                           1.0   \n",
       "3                     0.0                           0.0   \n",
       "4                     0.0                           0.0   \n",
       "..                    ...                           ...   \n",
       "704                   0.0                           0.0   \n",
       "705                   0.0                           0.0   \n",
       "706                   0.0                           0.0   \n",
       "707                   0.0                           0.0   \n",
       "708                   0.0                           0.0   \n",
       "\n",
       "     northern|northerner|northerners|arewa|almajiri  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               1.0   \n",
       "4                                               0.0   \n",
       "..                                              ...   \n",
       "704                                             1.0   \n",
       "705                                             0.0   \n",
       "706                                             0.0   \n",
       "707                                             0.0   \n",
       "708                                             0.0   \n",
       "\n",
       "     southern|southerner|southerners  hausa|hausas  fulani|fulanis  \\\n",
       "0                                0.0           0.0             0.0   \n",
       "1                                0.0           0.0             0.0   \n",
       "2                                0.0           0.0             0.0   \n",
       "3                                0.0           0.0             0.0   \n",
       "4                                0.0           0.0             0.0   \n",
       "..                               ...           ...             ...   \n",
       "704                              0.0           0.0             0.0   \n",
       "705                              0.0           0.0             0.0   \n",
       "706                              0.0           0.0             0.0   \n",
       "707                              0.0           0.0             0.0   \n",
       "708                              0.0           0.0             0.0   \n",
       "\n",
       "     yoruba|yorubas  igbo|ibo|ibos|igbos  \\\n",
       "0               0.0                  0.0   \n",
       "1               0.0                  0.0   \n",
       "2               0.0                  0.0   \n",
       "3               0.0                  0.0   \n",
       "4               0.0                  0.0   \n",
       "..              ...                  ...   \n",
       "704             0.0                  0.0   \n",
       "705             1.0                  0.0   \n",
       "706             0.0                  0.0   \n",
       "707             0.0                  0.0   \n",
       "708             1.0                  1.0   \n",
       "\n",
       "     women|woman|girl|girls|female|females  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "..                                     ...   \n",
       "704                                    0.0   \n",
       "705                                    0.0   \n",
       "706                                    0.0   \n",
       "707                                    0.0   \n",
       "708                                    0.0   \n",
       "\n",
       "     lgbt|lgbtq|lgbtq+|gay|gays|lesbian|lesbians|transgender|transgenders  \\\n",
       "0                                                  0.0                      \n",
       "1                                                  0.0                      \n",
       "2                                                  0.0                      \n",
       "3                                                  0.0                      \n",
       "4                                                  0.0                      \n",
       "..                                                 ...                      \n",
       "704                                                0.0                      \n",
       "705                                                0.0                      \n",
       "706                                                0.0                      \n",
       "707                                                0.0                      \n",
       "708                                                0.0                      \n",
       "\n",
       "     herdsmen|herdsman  eastern|easterner|easterners|biafra  \\\n",
       "0                  0.0                                  0.0   \n",
       "1                  0.0                                  0.0   \n",
       "2                  0.0                                  0.0   \n",
       "3                  0.0                                  0.0   \n",
       "4                  0.0                                  1.0   \n",
       "..                 ...                                  ...   \n",
       "704                0.0                                  0.0   \n",
       "705                0.0                                  0.0   \n",
       "706                0.0                                  0.0   \n",
       "707                0.0                                  0.0   \n",
       "708                0.0                                  0.0   \n",
       "\n",
       "                                      original_file  \\\n",
       "0    ../labels/raw/haaya_tweets_round_2_labeled.csv   \n",
       "1    ../labels/raw/haaya_tweets_round_2_labeled.csv   \n",
       "2    ../labels/raw/haaya_tweets_round_2_labeled.csv   \n",
       "3    ../labels/raw/haaya_tweets_round_2_labeled.csv   \n",
       "4    ../labels/raw/haaya_tweets_round_2_labeled.csv   \n",
       "..                                              ...   \n",
       "704  ../labels/raw/manu_tweets_round_2_labelled.csv   \n",
       "705  ../labels/raw/manu_tweets_round_2_labelled.csv   \n",
       "706  ../labels/raw/manu_tweets_round_2_labelled.csv   \n",
       "707  ../labels/raw/manu_tweets_round_2_labelled.csv   \n",
       "708  ../labels/raw/manu_tweets_round_2_labelled.csv   \n",
       "\n",
       "                                              labels  \n",
       "0    0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  \n",
       "1    1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  \n",
       "2    0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  \n",
       "3    0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  \n",
       "4    0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0  \n",
       "..                                               ...  \n",
       "704  0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  \n",
       "705  0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0  \n",
       "706  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  \n",
       "707  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  \n",
       "708  0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0  \n",
       "\n",
       "[709 rows x 17 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df = pd.read_csv(fourth_path / 'multilabels_v4.tsv', sep='\\t')\n",
    "# ml_df['labels'] = ml_df.apply(lambda row: ast.literal_eval(row['labels']), axis=1) \n",
    "ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d30715f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 279 from ../labels/raw/haaya_tweets_round_2_labeled.csv\n",
      "Dropping 0 empties from ../labels/raw/haaya_tweets_round_2_labeled.csv\n",
      "Dropping 56 unsures from ../labels/raw/haaya_tweets_round_2_labeled.csv\n",
      "Index(['index', 'class', 'text', 'christian|christians',\n",
      "       'muslim|muslims|islam|islamic',\n",
      "       'northern|northerner|northerners|arewa|almajiri',\n",
      "       'southern|southerner|southerners', 'hausa|hausas', 'fulani|fulanis',\n",
      "       'yoruba|yorubas', 'igbo|ibo|ibos|igbos',\n",
      "       'women|woman|girl|girls|female|females',\n",
      "       'lgbt|lgbtq|lgbtq+|gay|gays|lesbian|lesbians|transgender|transgenders',\n",
      "       'herdsmen|herdsman', 'eastern|easterner|easterners|biafra',\n",
      "       'original_file', 'labels'],\n",
      "      dtype='object')\n",
      "Loaded 240 from ../labels/raw/ibrahim_tweets_multi_labeled.csv\n",
      "Dropping 0 empties from ../labels/raw/ibrahim_tweets_multi_labeled.csv\n",
      "Dropping 0 unsures from ../labels/raw/ibrahim_tweets_multi_labeled.csv\n",
      "Index(['index', 'class', 'text', 'christian|christians',\n",
      "       'muslim|muslims|islam|islamic',\n",
      "       'northern|northerner|northerners|arewa|almajiri',\n",
      "       'southern|southerner|southerners', 'hausa|hausas', 'fulani|fulanis',\n",
      "       'yoruba|yorubas', 'igbo|ibo|ibos|igbos',\n",
      "       'women|woman|girl|girls|female|females',\n",
      "       'lgbt|lgbtq|lgbtq+|gay|gays|lesbian|lesbians|transgender|transgenders',\n",
      "       'herdsmen|herdsman', 'eastern|easterner|easterners|biafra',\n",
      "       'original_file', 'labels'],\n",
      "      dtype='object')\n",
      "Loaded 279 from ../labels/raw/manu_tweets_round_2_labelled.csv\n",
      "Dropping 0 empties from ../labels/raw/manu_tweets_round_2_labelled.csv\n",
      "Dropping 33 unsures from ../labels/raw/manu_tweets_round_2_labelled.csv\n",
      "Index(['index', 'class', 'text', 'christian|christians',\n",
      "       'muslim|muslims|islam|islamic',\n",
      "       'northern|northerner|northerners|arewa|almajiri',\n",
      "       'southern|southerner|southerners', 'hausa|hausas', 'fulani|fulanis',\n",
      "       'yoruba|yorubas', 'igbo|ibo|ibos|igbos',\n",
      "       'women|woman|girl|girls|female|females',\n",
      "       'lgbt|lgbtq|lgbtq+|gay|gays|lesbian|lesbians|transgender|transgenders',\n",
      "       'herdsmen|herdsman', 'eastern|easterner|easterners|biafra',\n",
      "       'original_file', 'labels'],\n",
      "      dtype='object')\n",
      "Kept 709 labels for training and testing.\n",
      "Loaded 279 from ../labels/raw/haaya_tweets_round_2_labeled.csv\n",
      "Dropping 0 empties from ../labels/raw/haaya_tweets_round_2_labeled.csv\n",
      "Dropping 56 unsures from ../labels/raw/haaya_tweets_round_2_labeled.csv\n",
      "Index(['index', 'class', 'text', 'christian|christians',\n",
      "       'muslim|muslims|islam|islamic',\n",
      "       'northern|northerner|northerners|arewa|almajiri',\n",
      "       'southern|southerner|southerners', 'hausa|hausas', 'fulani|fulanis',\n",
      "       'yoruba|yorubas', 'igbo|ibo|ibos|igbos',\n",
      "       'women|woman|girl|girls|female|females',\n",
      "       'lgbt|lgbtq|lgbtq+|gay|gays|lesbian|lesbians|transgender|transgenders',\n",
      "       'herdsmen|herdsman', 'eastern|easterner|easterners|biafra',\n",
      "       'original_file', 'raw_text', 'labels'],\n",
      "      dtype='object')\n",
      "Loaded 240 from ../labels/raw/ibrahim_tweets_multi_labeled.csv\n",
      "Dropping 0 empties from ../labels/raw/ibrahim_tweets_multi_labeled.csv\n",
      "Dropping 0 unsures from ../labels/raw/ibrahim_tweets_multi_labeled.csv\n",
      "Index(['index', 'class', 'text', 'christian|christians',\n",
      "       'muslim|muslims|islam|islamic',\n",
      "       'northern|northerner|northerners|arewa|almajiri',\n",
      "       'southern|southerner|southerners', 'hausa|hausas', 'fulani|fulanis',\n",
      "       'yoruba|yorubas', 'igbo|ibo|ibos|igbos',\n",
      "       'women|woman|girl|girls|female|females',\n",
      "       'lgbt|lgbtq|lgbtq+|gay|gays|lesbian|lesbians|transgender|transgenders',\n",
      "       'herdsmen|herdsman', 'eastern|easterner|easterners|biafra',\n",
      "       'original_file', 'raw_text', 'labels'],\n",
      "      dtype='object')\n",
      "Loaded 279 from ../labels/raw/manu_tweets_round_2_labelled.csv\n",
      "Dropping 0 empties from ../labels/raw/manu_tweets_round_2_labelled.csv\n",
      "Dropping 33 unsures from ../labels/raw/manu_tweets_round_2_labelled.csv\n",
      "Index(['index', 'class', 'text', 'christian|christians',\n",
      "       'muslim|muslims|islam|islamic',\n",
      "       'northern|northerner|northerners|arewa|almajiri',\n",
      "       'southern|southerner|southerners', 'hausa|hausas', 'fulani|fulanis',\n",
      "       'yoruba|yorubas', 'igbo|ibo|ibos|igbos',\n",
      "       'women|woman|girl|girls|female|females',\n",
      "       'lgbt|lgbtq|lgbtq+|gay|gays|lesbian|lesbians|transgender|transgenders',\n",
      "       'herdsmen|herdsman', 'eastern|easterner|easterners|biafra',\n",
      "       'original_file', 'raw_text', 'labels'],\n",
      "      dtype='object')\n",
      "Kept 709 labels for training and testing.\n"
     ]
    }
   ],
   "source": [
    "all_ml_df = load_multilabel_annotations_from_folder(files_folder=files_path, output_path=fourth_path, \n",
    "                                                    version=4, clean=False, drop_labels=False)\n",
    "all_ml_clean_df = load_multilabel_annotations_from_folder(files_folder=files_path, output_path=fourth_path, \n",
    "                                                    version=4, clean=True, drop_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c01c9520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 279 from ../labels/raw/haaya_tweets_round_2_labeled.csv\n",
      "Dropping 0 empties from ../labels/raw/haaya_tweets_round_2_labeled.csv\n",
      "Dropping 55 unsures from ../labels/raw/haaya_tweets_round_2_labeled.csv\n",
      "Index(['index', 'class', 'text', 'original_file', 'labels'], dtype='object')\n",
      "Loaded 240 from ../labels/raw/ibrahim_tweets_multi_labeled.csv\n",
      "Dropping 0 empties from ../labels/raw/ibrahim_tweets_multi_labeled.csv\n",
      "Dropping 0 unsures from ../labels/raw/ibrahim_tweets_multi_labeled.csv\n",
      "Index(['index', 'class', 'text', 'original_file', 'labels'], dtype='object')\n",
      "Loaded 279 from ../labels/raw/manu_tweets_round_2_labelled.csv\n",
      "Dropping 0 empties from ../labels/raw/manu_tweets_round_2_labelled.csv\n",
      "Dropping 33 unsures from ../labels/raw/manu_tweets_round_2_labelled.csv\n",
      "Index(['index', 'class', 'text', 'original_file', 'labels'], dtype='object')\n",
      "Kept 710 labels for training and testing.\n",
      "Loaded 279 from ../labels/raw/haaya_tweets_round_2_labeled.csv\n",
      "Dropping 0 empties from ../labels/raw/haaya_tweets_round_2_labeled.csv\n",
      "Dropping 55 unsures from ../labels/raw/haaya_tweets_round_2_labeled.csv\n",
      "Index(['index', 'class', 'text', 'original_file', 'raw_text', 'labels'], dtype='object')\n",
      "Loaded 240 from ../labels/raw/ibrahim_tweets_multi_labeled.csv\n",
      "Dropping 0 empties from ../labels/raw/ibrahim_tweets_multi_labeled.csv\n",
      "Dropping 0 unsures from ../labels/raw/ibrahim_tweets_multi_labeled.csv\n",
      "Index(['index', 'class', 'text', 'original_file', 'raw_text', 'labels'], dtype='object')\n",
      "Loaded 279 from ../labels/raw/manu_tweets_round_2_labelled.csv\n",
      "Dropping 0 empties from ../labels/raw/manu_tweets_round_2_labelled.csv\n",
      "Dropping 33 unsures from ../labels/raw/manu_tweets_round_2_labelled.csv\n",
      "Index(['index', 'class', 'text', 'original_file', 'raw_text', 'labels'], dtype='object')\n",
      "Kept 710 labels for training and testing.\n"
     ]
    }
   ],
   "source": [
    "all_ml_df = load_multilabel_annotations_from_folder(files_folder=files_path, output_path=fourth_path, \n",
    "                                                    version=4, clean=False, join_labels=False)\n",
    "all_ml_clean_df = load_multilabel_annotations_from_folder(files_folder=files_path, output_path=fourth_path, \n",
    "                                                    version=4, clean=True, join_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4b25f05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    333\n",
       "0    250\n",
       "1    127\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ml_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aebf1676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 12)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ml_df.iloc[0]['labels'], len(all_ml_df.iloc[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b59438e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fourth_path / 'multilabels_v4.csv')\n",
    "df['labels'] = df.apply(lambda row: ast.literal_eval(row['labels']), axis=1)\n",
    "num_labels = len(df.iloc[0]['labels'])\n",
    "train_df = df.sample(frac=0.7, random_state=0)\n",
    "eval_df = df.drop(train_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9e464b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['labels'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "37c7f29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_list = eval_df['labels'].to_list()[4]\n",
    "np.argwhere(_list == np.amax(_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8b950959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[element[0] for element in np.argwhere(np.array(_list) == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9cb19189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [8],\n",
       " [],\n",
       " [],\n",
       " [5, 10],\n",
       " [],\n",
       " [5, 10],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [3],\n",
       " [],\n",
       " [],\n",
       " [2, 5],\n",
       " [5, 10],\n",
       " [5, 10],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [5],\n",
       " [8],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [4],\n",
       " [1, 5, 10],\n",
       " [8],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [5, 10],\n",
       " [5, 10],\n",
       " [7],\n",
       " [5, 10],\n",
       " [],\n",
       " [5, 10],\n",
       " [5, 10],\n",
       " [],\n",
       " [7],\n",
       " [7, 8],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [7],\n",
       " [8, 9],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [2],\n",
       " [],\n",
       " [],\n",
       " [1, 2],\n",
       " [],\n",
       " [2],\n",
       " [],\n",
       " [8],\n",
       " [5],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [6],\n",
       " [],\n",
       " [2],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [2],\n",
       " [],\n",
       " [],\n",
       " [5],\n",
       " [5],\n",
       " [2],\n",
       " [],\n",
       " [2],\n",
       " [5],\n",
       " [],\n",
       " [5],\n",
       " [2],\n",
       " [4],\n",
       " [],\n",
       " [6],\n",
       " [],\n",
       " [],\n",
       " [8],\n",
       " [],\n",
       " [7],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [10],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [4],\n",
       " [],\n",
       " [7],\n",
       " [4],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [8],\n",
       " [1],\n",
       " [2],\n",
       " [7],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [2],\n",
       " [2],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [5],\n",
       " [11],\n",
       " [],\n",
       " [7],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [6],\n",
       " [],\n",
       " [6],\n",
       " [],\n",
       " [7],\n",
       " [],\n",
       " [],\n",
       " [6],\n",
       " [],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [],\n",
       " [],\n",
       " [5],\n",
       " [5],\n",
       " [],\n",
       " [],\n",
       " [5, 10],\n",
       " [5, 6],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [6],\n",
       " [4],\n",
       " [4, 5],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [4, 5],\n",
       " [4],\n",
       " [],\n",
       " [],\n",
       " [1, 4],\n",
       " [5, 10],\n",
       " [2],\n",
       " [10],\n",
       " [5, 10],\n",
       " [],\n",
       " [10],\n",
       " [],\n",
       " [5, 10],\n",
       " [],\n",
       " [5, 10],\n",
       " [5, 10],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [11],\n",
       " [6],\n",
       " [7],\n",
       " [7],\n",
       " [7, 8],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [2, 4, 5],\n",
       " [2],\n",
       " [],\n",
       " [2],\n",
       " [],\n",
       " [2],\n",
       " [1, 2],\n",
       " [3, 7],\n",
       " [],\n",
       " [],\n",
       " [6, 8],\n",
       " [],\n",
       " [4, 6],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_labels = []\n",
    "for eval_labels in eval_df['labels'].to_list():\n",
    "#     print(eval_labels)\n",
    "#     print(np.amax(eval_labels))\n",
    "#     print(np.argwhere(eval_labels == 1))\n",
    "    _labels.append([element[0] for element in np.argwhere(np.array(eval_labels) == 1).tolist()])\n",
    "_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b6646893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, label_ranking_average_precision_score\n",
    "\n",
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0133670d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.fit_transform(eval_df['labels'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6918de23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 12)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_mlb_labels = mlb.fit_transform(_labels)\n",
    "_mlb_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bdc7fd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 1 1 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 0 1 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for _mlb_label in _mlb_labels:\n",
    "    print(_mlb_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f5c4880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[1,2,0,1], [0,4], [3], [1,2]]\n",
    "y_pred = [[1,1,0,1], [1,4], [2], [1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9cbc04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = mlb.fit_transform(y_true)\n",
    "pred = mlb.fit_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "aecd17f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0]\n",
      " [1 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9b0226d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 0]\n",
      " [0 1 0 0 1]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8f0487c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(actual, pred, average = \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2fdc1855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.41666666666666663, 0.45, None)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(\n",
    "        y_true=actual,\n",
    "        y_pred=pred,\n",
    "        average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8476a483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/discoD/anaconda3/envs/world-bank/lib/python3.8/site-packages/sklearn/utils/validation.py:738: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  array = np.asarray(array, order=order, dtype=dtype)\n",
      "/media/discoD/anaconda3/envs/world-bank/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1054: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  y_true = check_array(y_true, ensure_2d=False)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to convert array of bytes/strings into decimal numbers with dtype='numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/media/discoD/anaconda3/envs/world-bank/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1508322/2704753948.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_ranking_average_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/discoD/anaconda3/envs/world-bank/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mlabel_ranking_average_precision_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \"\"\"\n\u001b[1;32m   1053\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/discoD/anaconda3/envs/world-bank/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    779\u001b[0m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    782\u001b[0m                     \u001b[0;34m\"Unable to convert array of bytes/strings \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m                     \u001b[0;34m\"into decimal numbers with dtype='numeric'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to convert array of bytes/strings into decimal numbers with dtype='numeric'"
     ]
    }
   ],
   "source": [
    "label_ranking_average_precision_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f87574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "world-bank",
   "language": "python",
   "name": "world-bank"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
